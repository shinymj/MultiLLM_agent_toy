{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "o3_mini = init_chat_model(\"openai:o3-mini\")\n",
    "claude_sonnet = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\", temperature=0)\n",
    "gemma3 = init_chat_model(\"ollama:gemma3:12b\", temperature=0)\n",
    "llama3_1 = init_chat_model(\"ollama:llama3.1:latest\", temperature=0)\n",
    "deepseek_r1 = init_chat_model(\"ollama:deepseek-r1:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what's your name\"\n",
    "print(\"OpenAI response:\", o3_mini.invoke(query))\n",
    "print(\"\\nClaude response:\", claude_sonnet.invoke(query))\n",
    "print(\"\\nGemma response:\", gemma3.invoke(query))\n",
    "print(\"\\nLlama3.1 response:\", llama3_1.invoke(query))\n",
    "print(\"\\nDeepseek-r1 response:\", deepseek_r1.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "file_path = \"biggen_bench_instruction_idx0.json\"\n",
    "\n",
    "def load_benchmark_data(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Load benchmark data from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def prepare_prompts(benchmark_data: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Prepare prompts by excluding reference_answer and score_rubric.\"\"\"\n",
    "    prompts = []\n",
    "    for item in benchmark_data:\n",
    "        prompt = {\n",
    "            \"id\": item[\"id\"],\n",
    "            \"capability\": item[\"capability\"],\n",
    "            \"task\": item[\"task\"],\n",
    "            \"instance_idx\": item[\"instance_idx\"],\n",
    "            \"system_prompt\": item[\"system_prompt\"],\n",
    "            \"input\": item[\"input\"],\n",
    "            # Exclude reference_answer and score_rubric\n",
    "        }\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def prepare_rubric(benchmark_data: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Prepare rubric including reference_answer and score_rubric.\"\"\"\n",
    "    rubric = []\n",
    "    for item in benchmark_data:\n",
    "        prompt = {\n",
    "            \"id\": item[\"id\"],\n",
    "            \"reference_answer\": item[\"reference_answer\"],\n",
    "            \"score_rubric\": item[\"score_rubric\"]\n",
    "        }\n",
    "        rubric.append(prompt)\n",
    "    return rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = load_benchmark_data(file_path)\n",
    "prompts = prepare_prompts(benchmark_data)\n",
    "rubric = prepare_rubric(benchmark_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'instruction_following_multi_task_inference_0', 'capability': 'instruction_following', 'task': 'multi_task_inference', 'instance_idx': 0, 'system_prompt': 'You are a helpful, respectful and honest assistant.', 'input': \"List all the terms referring to Elon Musk in a given text, and then rephrase each of them, excluding pronouns and 'Elon Musk'.\\nText: Elon Musk has had an eventful year. Those events could end up hurting your portfolio. The world's richest man repeatedly stoked controversy in 2023 by placing himself at the center of a number of scandals. Musk has had a penchant for involving himself in problematic issues this year: from endorsing - and then apologizing for - blatantly antisemitic tropes on X, to re-platforming conspiracy theorist Alex Jones and telling concerned advertisers (and Disney in particular) on X to go 'f**k' themselves. And he's suffered for them. X, nee Twitter, is now projected to bring in significantly less than the $4.5 billion it earned in the year before Musk took over the company.\"}\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful, respectful and honest assistant.\n",
      "List all the terms referring to Elon Musk in a given text, and then rephrase each of them, excluding pronouns and 'Elon Musk'.\n",
      "Text: Elon Musk has had an eventful year. Those events could end up hurting your portfolio. The world's richest man repeatedly stoked controversy in 2023 by placing himself at the center of a number of scandals. Musk has had a penchant for involving himself in problematic issues this year: from endorsing - and then apologizing for - blatantly antisemitic tropes on X, to re-platforming conspiracy theorist Alex Jones and telling concerned advertisers (and Disney in particular) on X to go 'f**k' themselves. And he's suffered for them. X, nee Twitter, is now projected to bring in significantly less than the $4.5 billion it earned in the year before Musk took over the company.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "You are a helpful, and informative assistant.\n",
      "Write a textbook-like material consisted of minimum two paragraphs that explains the Ito's Lemma. It should include how the Ito's Lemma induce the Black–Scholes model.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#prompts의 \"system_prompt\"와 \"input\"을 출력\n",
    "for prompt in prompts:\n",
    "    print(prompt[\"system_prompt\"])\n",
    "    print(prompt[\"input\"])\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts의 \"system_prompt\"와 \"input\"을 query로 사용하여 각 모델의 응답을 받아서 저장\n",
    "# query = prompts[0][\"input\"] + \", system_prompt: \" + prompts[0][\"system_prompt\"]\n",
    "\n",
    "system_prompt = prompts.get('system_prompt', '')\n",
    "user_input = prompts.get('input', '')\n",
    "print(user_input, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma response: content='Okay, here\\'s a list of terms referring to Elon Musk in the provided text, followed by rephrased versions excluding pronouns and \"Elon Musk\" itself:\\n\\n**Terms Referring to Elon Musk & Rephrased Versions:**\\n\\n1.  **Elon Musk** - *The world\\'s richest man*\\n2.  **Musk** - *He* (This is handled by the rephrasing of \"He\" below)\\n3.  **He** - *The individual* (This refers to actions attributed to him)\\n4.  **Those events** - *The occurrences* (Referring to the events impacting the portfolio)\\n5.  **The individual** - *The person* (Referring to the person involved in the scandals)\\n6.  **The person** - *The figure* (Referring to the person involved in the controversies)\\n7.  **The figure** - *The owner* (Referring to the person who took over the company)\\n\\n\\n\\n**Important Notes:**\\n\\n*   I\\'ve focused on terms *directly* referring to him or his actions.\\n*   The rephrased versions aim to convey the same meaning without using \"Elon Musk\" or pronouns.\\n*   Some terms are inherently tied to actions, so the rephrasing reflects that.' additional_kwargs={} response_metadata={'model': 'gemma3:12b', 'created_at': '2025-05-04T05:46:30.3016967Z', 'done': True, 'done_reason': 'stop', 'total_duration': 85290547300, 'load_duration': 2961648700, 'prompt_eval_count': 197, 'prompt_eval_duration': 22392737100, 'eval_count': 275, 'eval_duration': 59935071800, 'model_name': 'gemma3:12b'} id='run-6f28539e-7482-4f2e-801d-5795d14ff4bb-0' usage_metadata={'input_tokens': 197, 'output_tokens': 275, 'total_tokens': 472}\n"
     ]
    }
   ],
   "source": [
    "# print(\"OpenAI response:\", o3_mini.invoke(query))\n",
    "# print(\"\\nClaude response:\", claude_sonnet.invoke(query))\n",
    "print(\"\\nGemma response:\", gemma3.invoke(query))\n",
    "# print(\"\\nLlama3.1 response:\", llama3_1.invoke(query))\n",
    "# print(\"\\nDeepseek-r1 response:\", deepseek_r1.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: instruction_following_multi_task_inference_0\n",
      "System prompt: You are a helpful, respectful and honest assistant.\n",
      "User input: List all the terms referring to Elon Musk in a given text, and then rephrase each of them, excluding pronouns and 'Elon Musk'.\n",
      "Text: Elon Musk has had an eventful year. Those events could end up hurting your portfolio. The world's richest man repeatedly stoked controversy in 2023 by placing himself at the center of a number of scandals. Musk has had a penchant for involving himself in problematic issues this year: from endorsing - and then apologizing for - blatantly antisemitic tropes on X, to re-platforming conspiracy theorist Alex Jones and telling concerned advertisers (and Disney in particular) on X to go 'f**k' themselves. And he's suffered for them. X, nee Twitter, is now projected to bring in significantly less than the $4.5 billion it earned in the year before Musk took over the company.\n",
      "Error invoking model for prompt instruction_following_multi_task_inference_0: 'str' object has no attribute 'items'\n",
      "---\n",
      "Processing prompt: instruction_following_education_content_creation_0\n",
      "System prompt: You are a helpful, and informative assistant.\n",
      "User input: Write a textbook-like material consisted of minimum two paragraphs that explains the Ito's Lemma. It should include how the Ito's Lemma induce the Black–Scholes model.\n",
      "Error invoking model for prompt instruction_following_education_content_creation_0: 'str' object has no attribute 'items'\n",
      "---\n",
      "Processed 2 prompts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemma3_results = []\n",
    "\n",
    "# Process each prompt in the list\n",
    "for prompt in prompts:\n",
    "    # Extract the required fields\n",
    "    system_prompt = prompt.get('system_prompt', '')\n",
    "    user_input = prompt.get('input', '')\n",
    "    \n",
    "    # Print for verification\n",
    "    print(f\"Processing prompt: {prompt.get('id', 'unknown')}\")\n",
    "    print(f\"System prompt: {system_prompt}\")\n",
    "    print(f\"User input: {user_input}\")\n",
    "    \n",
    "    # Invoke your model with the extracted parameters\n",
    "    # The exact syntax depends on your model's API\n",
    "    try:\n",
    "        # Example invocation (adjust according to your model's API)\n",
    "        response = gemma3.invoke(\n",
    "            user_input, \n",
    "            system_prompt=system_prompt\n",
    "            # Add any other parameters your model.invoke() requires\n",
    "        )\n",
    "        \n",
    "        # Store the result along with the prompt information\n",
    "        result = {\n",
    "            \"prompt_id\": prompt.get('id', ''),\n",
    "            \"system_prompt\": system_prompt,\n",
    "            \"input\": user_input,\n",
    "            \"response\": response\n",
    "        }\n",
    "        gemma3_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking model for prompt {prompt.get('id', '')}: {e}\")\n",
    "        # You might want to add the error to results as well\n",
    "        gemma3_results.append({\n",
    "            \"prompt_id\": prompt.get('id', ''),\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "    \n",
    "    print(\"---\")\n",
    "\n",
    "# Now 'results' contains all the responses\n",
    "print(f\"Processed {len(gemma3_results)} prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: instruction_following_multi_task_inference_0\n",
      "System prompt: You are a helpful, respectful and honest assistant.\n",
      "User input: List all the terms referring to Elon Musk in a given text, and then rephrase each of them, excluding pronouns and 'Elon Musk'.\n",
      "Text: Elon Musk has had an eventful year. Those events could end up hurting your portfolio. The world's richest man repeatedly stoked controversy in 2023 by placing himself at the center of a number of scandals. Musk has had a penchant for involving himself in problematic issues this year: from endorsing - and then apologizing for - blatantly antisemitic tropes on X, to re-platforming conspiracy theorist Alex Jones and telling concerned advertisers (and Disney in particular) on X to go 'f**k' themselves. And he's suffered for them. X, nee Twitter, is now projected to bring in significantly less than the $4.5 billion it earned in the year before Musk took over the company.\n",
      "---\n",
      "Processing prompt: instruction_following_education_content_creation_0\n",
      "System prompt: You are a helpful, and informative assistant.\n",
      "User input: Write a textbook-like material consisted of minimum two paragraphs that explains the Ito's Lemma. It should include how the Ito's Lemma induce the Black–Scholes model.\n",
      "---\n",
      "Processed 2 prompts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemma3_results = []\n",
    "\n",
    "# Process each prompt in the list\n",
    "for prompt in prompts:\n",
    "    # Extract the required fields\n",
    "    system_prompt = prompt.get('system_prompt', '')\n",
    "    user_input = prompt.get('input', '')\n",
    "    \n",
    "    # Invoke your model with the extracted parameters\n",
    "    # The exact syntax depends on your model's API\n",
    "    try:\n",
    "        # Example invocation (adjust according to your model's API)\n",
    "        response = gemma3.invoke(\n",
    "            user_input, \n",
    "            config={\"system_prompt\": system_prompt}\n",
    "            # Add any other parameters your model.invoke() requires\n",
    "        )\n",
    "        \n",
    "        # Store the result along with the prompt information\n",
    "        result = {\n",
    "            \"prompt_id\": prompt.get('id', ''),\n",
    "            \"response\": response\n",
    "        }\n",
    "        gemma3_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking model for prompt {prompt.get('id', '')}: {e}\")\n",
    "        # You might want to add the error to results as well\n",
    "        gemma3_results.append({\n",
    "            \"prompt_id\": prompt.get('id', ''),\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "    \n",
    "    print(\"---\")\n",
    "\n",
    "# Now 'results' contains all the responses\n",
    "print(f\"Processed {len(gemma3_results)} prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt_id': 'instruction_following_multi_task_inference_0',\n",
       "  'system_prompt': 'You are a helpful, respectful and honest assistant.',\n",
       "  'input': \"List all the terms referring to Elon Musk in a given text, and then rephrase each of them, excluding pronouns and 'Elon Musk'.\\nText: Elon Musk has had an eventful year. Those events could end up hurting your portfolio. The world's richest man repeatedly stoked controversy in 2023 by placing himself at the center of a number of scandals. Musk has had a penchant for involving himself in problematic issues this year: from endorsing - and then apologizing for - blatantly antisemitic tropes on X, to re-platforming conspiracy theorist Alex Jones and telling concerned advertisers (and Disney in particular) on X to go 'f**k' themselves. And he's suffered for them. X, nee Twitter, is now projected to bring in significantly less than the $4.5 billion it earned in the year before Musk took over the company.\",\n",
       "  'response': AIMessage(content='Okay, here\\'s a list of terms referring to Elon Musk in the provided text, followed by rephrased versions excluding pronouns and \"Elon Musk\" itself:\\n\\n**Terms Referring to Elon Musk & Rephrased Versions:**\\n\\n1.  **Elon Musk** - *The world\\'s richest man*\\n2.  **Musk** - *He* (This is excluded from the rephrasing as per the instructions)\\n3.  **Those events** - *His actions*\\n4.  **He** - *The individual* (Excluded as per instructions)\\n5.  **The individual** - *The person* (Used to avoid repetition)\\n6.  **The person** - *The figure* (Used to avoid repetition)\\n7.  **The figure** - *The subject* (Used to avoid repetition)\\n8.  **The subject** - *The owner* (Used to avoid repetition)\\n9.  **The owner** - *The leader* (Used to avoid repetition)\\n\\n\\n\\n**Note:** Some of these rephrased versions are quite general. The best choice for a specific context would depend on the surrounding sentences and the desired level of detail.', additional_kwargs={}, response_metadata={'model': 'gemma3:12b', 'created_at': '2025-05-04T06:42:49.260578Z', 'done': True, 'done_reason': 'stop', 'total_duration': 82237053300, 'load_duration': 6914356300, 'prompt_eval_count': 183, 'prompt_eval_duration': 20511533500, 'eval_count': 255, 'eval_duration': 54810600200, 'model_name': 'gemma3:12b'}, id='run-d0a7e6f5-a81b-4f3e-a5c3-c3de24b4fb2b-0', usage_metadata={'input_tokens': 183, 'output_tokens': 255, 'total_tokens': 438})},\n",
       " {'prompt_id': 'instruction_following_education_content_creation_0',\n",
       "  'system_prompt': 'You are a helpful, and informative assistant.',\n",
       "  'input': \"Write a textbook-like material consisted of minimum two paragraphs that explains the Ito's Lemma. It should include how the Ito's Lemma induce the Black–Scholes model.\",\n",
       "  'response': AIMessage(content=\"## Ito's Lemma: A Calculus for Stochastic Processes\\n\\nIto's Lemma is a fundamental result in stochastic calculus, analogous to the chain rule in ordinary calculus, but adapted for functions of stochastic processes.  Unlike ordinary calculus where we deal with functions of deterministic variables, Ito's Lemma deals with functions of *stochastic* variables – variables that change randomly over time.  Specifically, it describes how a function *f(t, X<sub>t</sub>)* changes with respect to time *t* and the stochastic process *X<sub>t</sub>*, which is typically a diffusion process like Brownian motion (also known as a Wiener process).  The core idea is that the change in *f* isn't just due to the change in *X<sub>t</sub>*, but also due to the *squared* rate of change of *X<sub>t</sub>* itself.  Mathematically, Ito's Lemma states:\\n\\nd*f*(t, X<sub>t</sub>) = (∂*f*/∂t + μ(t, X<sub>t</sub>) ∂*f*/∂x + ½ σ(t, X<sub>t</sub>)<sup>2</sup> ∂<sup>2</sup>*f*/∂x<sup>2</sup>) dt + σ(t, X<sub>t</sub>) ∂*f*/∂x d*W<sub>t</sub>*\\n\\nWhere:\\n* *f(t, X<sub>t</sub>)* is a twice-differentiable function of time *t* and the stochastic process *X<sub>t</sub>*.\\n* *μ(t, X<sub>t</sub>)* is the drift coefficient of the stochastic process *X<sub>t</sub>*.\\n* *σ(t, X<sub>t</sub>)* is the diffusion coefficient of the stochastic process *X<sub>t</sub>*.\\n* *W<sub>t</sub>* is a Wiener process (Brownian motion).\\n* ∂*f*/∂t, ∂*f*/∂x, and ∂<sup>2</sup>*f*/∂x<sup>2</sup> represent the partial derivatives of *f* with respect to *t* and *x*.\\n* dt represents an infinitesimal change in time.\\n* d*W<sub>t</sub>* represents an infinitesimal change in the Wiener process.\\n\\nThe crucial term, ½ σ(t, X<sub>t</sub>)<sup>2</sup> ∂<sup>2</sup>*f*/∂x<sup>2</sup>, is the Ito correction term. It arises because the infinitesimal change in a stochastic process isn't just proportional to its instantaneous rate of change; it also has a component related to the variance of that rate of change.  This term is what distinguishes Ito's Lemma from the ordinary chain rule and is essential for correctly modeling phenomena driven by randomness.\\n\\n\\n\\n## Ito's Lemma and the Black-Scholes Model\\n\\nThe Black-Scholes model, a cornerstone of modern financial mathematics, relies heavily on Ito's Lemma. The model aims to price European options – contracts that give the holder the right, but not the obligation, to buy (call option) or sell (put option) an asset at a predetermined price (the strike price) on a specific date (the expiration date).  The underlying asset's price, *S<sub>t</sub>*, is typically assumed to follow a geometric Brownian motion, meaning its price changes randomly over time, but with a predictable drift and volatility.  Specifically, d*S<sub>t</sub>* = μ dt + σ d*W<sub>t</sub>*, where μ is the expected rate of return and σ is the volatility.  To derive the Black-Scholes partial differential equation (PDE), which governs the price of an option, *V(t, S<sub>t</sub>)*, we apply Ito's Lemma to the function *V(t, S<sub>t</sub>)*.  \\n\\nApplying Ito's Lemma, we get:\\n\\nd*V* = (∂*V*/∂t + μ ∂*V*/∂S + ½ σ<sup>2</sup> ∂<sup>2</sup>*V*/∂S<sup>2</sup>) dt + σ ∂*V*/∂S d*W<sub>t</sub>*\\n\\nWe then equate this change in the option price to the expected change in the option price, using the risk-neutral pricing principle. This principle states that we can price options as if the expected return on the underlying asset were the risk-free rate.  This leads to the famous Black-Scholes PDE:\\n\\n∂*V*/∂t + r *V* + ½ σ<sup>2</sup> ∂<sup>2</sup>*V*/∂S<sup>2</sup> - rS ∂*V*/∂S = 0\\n\\nWhere *r* is the risk-free interest rate.  Solving this PDE, subject to appropriate boundary conditions (the option's payoff at expiration), yields the Black-Scholes formula for option pricing.  Therefore, Ito's Lemma is not just a mathematical tool; it's the *foundation* upon which the Black-Scholes model, and much of modern financial derivative pricing, is built. Without it, we wouldn't have a framework to accurately model and price options in a world driven by random fluctuations.\", additional_kwargs={}, response_metadata={'model': 'gemma3:12b', 'created_at': '2025-05-04T06:46:57.6400947Z', 'done': True, 'done_reason': 'stop', 'total_duration': 248375987700, 'load_duration': 99516600, 'prompt_eval_count': 45, 'prompt_eval_duration': 5074680600, 'eval_count': 1054, 'eval_duration': 243201138100, 'model_name': 'gemma3:12b'}, id='run-918454a4-a8c3-4a74-b381-2b5f375da0bd-0', usage_metadata={'input_tokens': 45, 'output_tokens': 1054, 'total_tokens': 1099})}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-model serial response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_prompts(model, model_name, prompts):\n",
    "    \"\"\"\n",
    "    Process all prompts using the specified model.\n",
    "    \n",
    "    Args:\n",
    "        model: The initialized model object\n",
    "        model_name: String name of the model for recording\n",
    "        prompts: List of prompt dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        List of result dictionaries\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Process each prompt in the list\n",
    "    for prompt in prompts:\n",
    "        # Extract the required fields\n",
    "        system_prompt = prompt.get('system_prompt', '')\n",
    "        user_input = prompt.get('input', '')\n",
    "        \n",
    "        print(f\"Processing prompt {prompt.get('id', '')} with model {model_name}\")\n",
    "        \n",
    "        # Invoke your model with the extracted parameters\n",
    "        try:\n",
    "            # Invoke the model with standardized parameters\n",
    "            response = model.invoke(\n",
    "                user_input, \n",
    "                config={\"system_prompt\": system_prompt}\n",
    "                # Add any other parameters your model.invoke() requires\n",
    "            )\n",
    "            \n",
    "            # Store the result with model name\n",
    "            result = {\n",
    "                \"id\": prompt.get('id', ''),\n",
    "                \"model_name\": model_name,\n",
    "                \"response\": response\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error invoking {model_name} for prompt {prompt.get('id', '')}: {e}\")\n",
    "            results.append({\n",
    "                \"id\": prompt.get('id', ''),\n",
    "                \"model_name\": model_name,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "        \n",
    "        print(\"---\")\n",
    "\n",
    "    print(f\"Processed {len(results)} prompts with {model_name}\")\n",
    "    print(\"--------------------------------\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt instruction_following_multi_task_inference_0 with model gemma3\n",
      "---\n",
      "Processing prompt instruction_following_education_content_creation_0 with model gemma3\n",
      "---\n",
      "Processed 2 prompts with gemma3\n",
      "Processing prompt instruction_following_multi_task_inference_0 with model llama3_1\n",
      "---\n",
      "Processing prompt instruction_following_education_content_creation_0 with model llama3_1\n",
      "---\n",
      "Processed 2 prompts with llama3_1\n",
      "Processing prompt instruction_following_multi_task_inference_0 with model deepseek_r1\n",
      "---\n",
      "Processing prompt instruction_following_education_content_creation_0 with model deepseek_r1\n",
      "---\n",
      "Processed 2 prompts with deepseek_r1\n"
     ]
    }
   ],
   "source": [
    "# Process prompts with each model\n",
    "gemma3_results = process_model_prompts(gemma3, \"gemma3\", prompts)\n",
    "llama3_1_results = process_model_prompts(llama3_1, \"llama3_1\", prompts)\n",
    "deepseek_r1_results = process_model_prompts(deepseek_r1, \"deepseek_r1\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'instruction_following_multi_task_inference_0',\n",
       "  'model_name': 'gemma3',\n",
       "  'response': AIMessage(content='Okay, here\\'s a list of terms referring to Elon Musk in the provided text, followed by rephrased versions excluding pronouns and \"Elon Musk\" itself:\\n\\n**Terms Referring to Elon Musk & Rephrased Versions:**\\n\\n1.  **Elon Musk** - *The world\\'s richest man*\\n2.  **Musk** - *He* (This is excluded from the rephrasing as per the instructions)\\n3.  **Those events** - *His actions*\\n4.  **He** - *The individual* (Excluded as per instructions)\\n5.  **The individual** - *The person* (Used to avoid repetition)\\n6.  **The person** - *The figure* (Used to avoid repetition)\\n7.  **The figure** - *The subject* (Used to avoid repetition)\\n8.  **The subject** - *The owner* (Used to avoid repetition)\\n9.  **The owner** - *The leader* (Used to avoid repetition)\\n\\n\\n\\n**Note:** Some of these rephrased versions are quite general. The best choice for a specific context would depend on the surrounding sentences and the desired level of detail.', additional_kwargs={}, response_metadata={'model': 'gemma3:12b', 'created_at': '2025-05-04T08:56:16.2940699Z', 'done': True, 'done_reason': 'stop', 'total_duration': 90662945900, 'load_duration': 7797622600, 'prompt_eval_count': 183, 'prompt_eval_duration': 22963631500, 'eval_count': 255, 'eval_duration': 59899538700, 'model_name': 'gemma3:12b'}, id='run-7e1b5693-16d1-4ec1-a0c1-7a03c70c0927-0', usage_metadata={'input_tokens': 183, 'output_tokens': 255, 'total_tokens': 438})},\n",
       " {'id': 'instruction_following_education_content_creation_0',\n",
       "  'model_name': 'gemma3',\n",
       "  'response': AIMessage(content=\"## Ito's Lemma: A Calculus for Stochastic Processes\\n\\nIto's Lemma is a fundamental result in stochastic calculus, analogous to the chain rule in ordinary calculus, but adapted for functions of stochastic processes.  Unlike ordinary calculus where we deal with functions of deterministic variables, Ito's Lemma deals with functions of *stochastic* variables – variables that change randomly over time.  Specifically, it describes how a function *f(t, X<sub>t</sub>)* changes with respect to time *t* and the stochastic process *X<sub>t</sub>*, which is typically a diffusion process like Brownian motion (also known as a Wiener process).  The core idea is that the change in *f* isn't just due to the change in *X<sub>t</sub>*, but also due to the *squared* rate of change of *X<sub>t</sub>* itself.  Mathematically, Ito's Lemma states:\\n\\nd*f*(t, X<sub>t</sub>) = (∂*f*/∂t + μ(t, X<sub>t</sub>) ∂*f*/∂x + ½ σ(t, X<sub>t</sub>)<sup>2</sup> ∂<sup>2</sup>*f*/∂x<sup>2</sup>) dt + σ(t, X<sub>t</sub>) ∂*f*/∂x d*W<sub>t</sub>*\\n\\nWhere:\\n* *f(t, X<sub>t</sub>)* is a twice-differentiable function of time *t* and the stochastic process *X<sub>t</sub>*.\\n* *μ(t, X<sub>t</sub>)* is the drift coefficient of the stochastic process *X<sub>t</sub>*.\\n* *σ(t, X<sub>t</sub>)* is the diffusion coefficient of the stochastic process *X<sub>t</sub>*.\\n* *W<sub>t</sub>* is a Wiener process (Brownian motion).\\n* ∂*f*/∂t, ∂*f*/∂x, and ∂<sup>2</sup>*f*/∂x<sup>2</sup> represent the partial derivatives of *f* with respect to *t* and *x*.\\n* dt represents an infinitesimal change in time.\\n* d*W<sub>t</sub>* represents an infinitesimal change in the Wiener process.\\n\\nThe crucial term, ½ σ(t, X<sub>t</sub>)<sup>2</sup> ∂<sup>2</sup>*f*/∂x<sup>2</sup>, is the Ito correction term. It arises because the infinitesimal change in a stochastic process isn't just proportional to its instantaneous rate of change; it also has a component related to the variance of that rate of change.  This term is what distinguishes Ito's Lemma from the ordinary chain rule and is essential for correctly modeling phenomena driven by randomness.\\n\\n\\n\\n## Ito's Lemma and the Black-Scholes Model\\n\\nThe Black-Scholes model, a cornerstone of modern financial mathematics, relies heavily on Ito's Lemma. The model aims to price European options – contracts that give the holder the right, but not the obligation, to buy (call option) or sell (put option) an asset at a predetermined price (the strike price) on a specific date (the expiration date).  The underlying asset's price, *S<sub>t</sub>*, is typically assumed to follow a geometric Brownian motion, meaning its price changes randomly over time, but with a predictable drift and volatility.  Specifically, d*S<sub>t</sub>* = μ dt + σ d*W<sub>t</sub>*, where μ is the expected rate of return and σ is the volatility.  To derive the Black-Scholes partial differential equation (PDE), which governs the price of an option, *V(t, S<sub>t</sub>)*, we apply Ito's Lemma to the function *V(t, S<sub>t</sub>)*.  \\n\\nApplying Ito's Lemma, we get:\\n\\nd*V* = (∂*V*/∂t + μ ∂*V*/∂S + ½ σ<sup>2</sup> ∂<sup>2</sup>*V*/∂S<sup>2</sup>) dt + σ ∂*V*/∂S d*W<sub>t</sub>*\\n\\nWe then equate this change in the option price to the expected change in the option price, using the risk-neutral pricing principle. This principle states that we can price options as if the expected return on the underlying asset were the risk-free rate.  This leads to the famous Black-Scholes PDE:\\n\\n∂*V*/∂t + r *V* + ½ σ<sup>2</sup> ∂<sup>2</sup>*V*/∂S<sup>2</sup> - rS ∂*V*/∂S = 0\\n\\nWhere *r* is the risk-free interest rate.  Solving this PDE, subject to appropriate boundary conditions (the option's payoff at expiration), yields the Black-Scholes formula for option pricing.  Therefore, Ito's Lemma is not just a mathematical tool; it's the *foundation* upon which the Black-Scholes model, and much of modern financial derivative pricing, is built. Without it, we wouldn't have a framework to accurately model and price options in a world driven by random fluctuations.\", additional_kwargs={}, response_metadata={'model': 'gemma3:12b', 'created_at': '2025-05-04T09:03:35.2498801Z', 'done': True, 'done_reason': 'stop', 'total_duration': 438952859400, 'load_duration': 140079300, 'prompt_eval_count': 45, 'prompt_eval_duration': 7544327000, 'eval_count': 1054, 'eval_duration': 431267921700, 'model_name': 'gemma3:12b'}, id='run-f08fa04c-d3a2-41d0-a3b6-843dd4b72e82-0', usage_metadata={'input_tokens': 45, 'output_tokens': 1054, 'total_tokens': 1099})},\n",
       " {'id': 'instruction_following_multi_task_inference_0',\n",
       "  'model_name': 'llama3_1',\n",
       "  'response': AIMessage(content=\"Here are the terms referring to Elon Musk:\\n\\n1. **Elon Musk**\\n2. The world's richest man\\n3. Musk (referring to him)\\n4. He (referring to him)\\n\\nRephrased versions, excluding pronouns and 'Elon Musk':\\n\\n1. **The CEO of SpaceX and Tesla**\\n2. The individual with the highest net worth in the world\\n3. The owner of X (formerly Twitter)\\n4. The founder of Neuralink and The Boring Company\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-05-04T09:04:05.2183847Z', 'done': True, 'done_reason': 'stop', 'total_duration': 29961864700, 'load_duration': 11373898400, 'prompt_eval_count': 187, 'prompt_eval_duration': 1038893200, 'eval_count': 103, 'eval_duration': 17513920500, 'model_name': 'llama3.1:latest'}, id='run-b53a5218-2dbd-469f-a285-926ca2ef5ef8-0', usage_metadata={'input_tokens': 187, 'output_tokens': 103, 'total_tokens': 290})},\n",
       " {'id': 'instruction_following_education_content_creation_0',\n",
       "  'model_name': 'llama3_1',\n",
       "  'response': AIMessage(content=\"**Ito's Lemma**\\n\\nIto's Lemma is a fundamental concept in stochastic calculus, named after Kiyoshi Ito, who first introduced it in 1944. It provides a way to calculate the differential of a function of a stochastic process, specifically a Wiener process (also known as Brownian motion). The lemma states that if we have a stochastic process `X(t)` and a twice-differentiable function `f(X(t), t)`, then the differential of `f` is given by:\\n\\n`d f = (∂f/∂t + (∂f/∂x) \\\\* dX + (1/2) \\\\* (∂^2f/∂x^2) \\\\* dX^2) dt`\\n\\nwhere `dX` and `dX^2` are the differential of the stochastic process and its squared term, respectively. This equation is a key result in stochastic calculus, as it allows us to derive the dynamics of functions of stochastic processes.\\n\\n**Derivation of the Black-Scholes Model**\\n\\nIto's Lemma plays a crucial role in the derivation of the Black-Scholes model, which is a widely used option pricing model. In 1973, Fischer Black and Myron Scholes developed this model by applying Ito's Lemma to a stock price process `S(t)` and an option payoff function `f(S(t), t)`. They assumed that the stock price follows a geometric Brownian motion, which is a stochastic process with the following dynamics:\\n\\n`dS = μ S dt + σ S dW`\\n\\nwhere `μ` is the drift term, `σ` is the volatility, and `dW` is the differential of a Wiener process. By applying Ito's Lemma to an option payoff function `f(S(t), t)`, they obtained the following partial differential equation (PDE):\\n\\n`(∂f/∂t + μ S (∂f/∂S) + (1/2) \\\\* σ^2 S^2 (\\\\partial^2f/∂S^2)) dt = r f`\\n\\nwhere `r` is the risk-free interest rate. This PDE, known as the Black-Scholes equation, describes the dynamics of option prices in terms of the underlying stock price and time to maturity. By solving this equation, we can obtain the fair value of an option, which is a fundamental concept in finance.\\n\\nThe Black-Scholes model has been widely used for decades to price options on stocks, indices, and other assets. Its success lies in its ability to provide accurate prices under certain assumptions about market dynamics, such as constant volatility and no arbitrage opportunities. However, the model has also been criticized for its limitations, including the assumption of lognormal stock returns and the absence of jumps or other non-Gaussian effects. Despite these limitations, the Black-Scholes model remains a cornerstone of financial engineering and continues to be refined and extended by researchers and practitioners.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-05-04T09:06:04.9340362Z', 'done': True, 'done_reason': 'stop', 'total_duration': 119710665900, 'load_duration': 37516400, 'prompt_eval_count': 46, 'prompt_eval_duration': 762152100, 'eval_count': 612, 'eval_duration': 118909996900, 'model_name': 'llama3.1:latest'}, id='run-825e1f73-e556-4359-9dc2-5eb7744ba01d-0', usage_metadata={'input_tokens': 46, 'output_tokens': 612, 'total_tokens': 658})},\n",
       " {'id': 'instruction_following_multi_task_inference_0',\n",
       "  'model_name': 'deepseek_r1',\n",
       "  'response': AIMessage(content='<think>\\nOkay, so I need to figure out how to approach this query. The user has provided a text about Elon Musk and wants me to list all terms referring to him, then rephrase each without using pronouns or his name.\\n\\nFirst, I\\'ll read through the text carefully. The text mentions \"Elon Musk\" multiple times, so that\\'s the main term to focus on. Then, looking for other terms: \"the world\\'s richest man,\" \"Musk,\" and \"he.\" Those are the pronouns, so they need to be excluded.\\n\\nNext, I\\'ll list each instance where his name is used. Each time \"Elon Musk\" appears, I should rephrase it with another term. For example, \"the world\\'s richest man\" can replace \"Elon Musk.\"\\n\\nI also notice that \"Musk\" and \"he\" are pronouns referring to him, so they need to be excluded as well. So in the text, wherever his name is mentioned, I\\'ll use \"the world\\'s richest man\" instead.\\n\\nNow, I\\'ll go through each sentence and replace those terms accordingly. The response should list all instances where his name is used and then rephrase them without pronouns or his name.\\n\\nI think that covers it. I just need to make sure each term is accurately replaced and the sentences still make sense after rephrasing.\\n</think>\\n\\nHere are the terms referring to Elon Musk in the given text, followed by their rephrased versions:\\n\\n1. **Elon Musk** → The world\\'s richest man  \\n2. **Musk** → The world\\'s richest man  \\n3. **he** → The world\\'s richest man  \\n\\nThe rephrased sentences would be:  \\n\\n\"Those events could end up hurting your portfolio. The world\\'s richest man has had an eventful year, and these events might negatively impact your investments.\"  \\n\\n\"The world\\'s richest man has sparked controversy in 2023 by involving himself in several scandals.\"  \\n\\n\"This year, the world\\'s richest man has been involved in problematic issues, including endorsing—and later apologizing for—antisemitic tropes on X, re-platforming conspiracy theorist Alex Jones, and making offensive remarks to advertisers like Disney.\"  \\n\\n\"X, formerly known as Twitter, is expected to generate significantly less revenue than the $4.5 billion it earned before the world\\'s richest man took control of the company.\"', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-05-04T09:08:07.7355594Z', 'done': True, 'done_reason': 'stop', 'total_duration': 122797637900, 'load_duration': 6037589600, 'prompt_eval_count': 180, 'prompt_eval_duration': 994026200, 'eval_count': 490, 'eval_duration': 115764579700, 'model_name': 'deepseek-r1:8b'}, id='run-5ffe8d93-3de8-48a1-9770-1db3ab24f5f4-0', usage_metadata={'input_tokens': 180, 'output_tokens': 490, 'total_tokens': 670})},\n",
       " {'id': 'instruction_following_education_content_creation_0',\n",
       "  'model_name': 'deepseek_r1',\n",
       "  'response': AIMessage(content=\"<think>\\nOkay, so I need to write about Ito's Lemma and how it leads to the Black-Scholes model. Hmm, where do I start? I remember that Ito's Lemma is related to stochastic calculus, which deals with processes that have uncertainty, like stock prices in finance.\\n\\nI think Ito's Lemma is used when you have a process that's both a function of time and another variable, maybe like the value of an asset. So if you have a function S(t, x) where t is time and x is the position, then the lemma helps relate the change in S to its partial derivatives.\\n\\nWait, I should probably look up the exact formula. From what I recall, Ito's Lemma involves the differential of a function multiplied by a stochastic differential. So it might be something like dS = (partial S / partial t + partial S / partial x) dt + (partial S / partial x) dx.\\n\\nRight, so this is similar to the Taylor expansion but for stochastic processes. It allows us to approximate changes in S considering both deterministic and random parts. That makes sense because stock prices can be influenced by both predictable trends (dt part) and random fluctuations (dx part).\\n\\nNow, how does this lead to the Black-Scholes model? I know that Black-Scholes is used to price options, so it must involve some kind of differential equation. Maybe Ito's Lemma helps set up a PDE that can be solved to find the option price.\\n\\nIn the Black-Scholes framework, the stock price follows a geometric Brownian motion, which is a type of stochastic process. So S(t) = S0 * e^(rt - 0.5σ²t + σx t), where x is a Weiner process. Ito's Lemma would then be applied to this function.\\n\\nIf we let V(t, x) be the value of an option at time t with state x (maybe the stock price), then applying Ito's Lemma would give us dV = some combination of derivatives of V and the stochastic differential dx.\\n\\nI think the Black-Scholes equation comes from setting up a partial differential equation based on the dynamics of the stock price. So, by applying Ito's Lemma to V(t,x) and knowing how S(t,x) evolves, we can derive an equation that relates the change in V over time to its spatial derivatives.\\n\\nThis leads to the Black-Scholes formula, which gives the price of a call or put option based on the current stock price, volatility, time to maturity, risk-free rate, and dividend yield. So Ito's Lemma is fundamental in deriving the pricing model that underpins much of modern finance.\\n\\nWait, did I miss anything? Maybe I should structure this into two paragraphs: one explaining Ito's Lemma generally and another on its application in Black-Scholes. Also, make sure to mention stochastic calculus and how it applies to financial models.\\n</think>\\n\\n**Ito's Lemma and Its Application in the Black-Scholes Model**\\n\\nIto's Lemma is a cornerstone in the field of stochastic calculus, providing a framework for analyzing processes that incorporate both deterministic and random elements. It is particularly valuable in finance, where stock prices are subject to uncertainty, often modeled as stochastic processes.\\n\\n**Understanding Ito's Lemma:**\\nIto's Lemma states that for a function \\\\( S(t, x) \\\\), where \\\\( t \\\\) represents time and \\\\( x \\\\) denotes the state (such as the price of an asset), the change in \\\\( S \\\\) can be expressed as:\\n\\\\[ dS = \\\\left( \\\\frac{\\\\partial S}{\\\\partial t} + \\\\frac{\\\\partial S}{\\\\partial x} \\\\right) dt + \\\\frac{\\\\partial S}{\\\\partial x} dx \\\\]\\nThis equation extends the Taylor expansion to stochastic processes, allowing for the approximation of changes in \\\\( S \\\\) considering both deterministic trends (captured by \\\\( dt \\\\)) and random fluctuations (represented by \\\\( dx \\\\)).\\n\\n**Application in the Black-Scholes Model:**\\nThe Black-Scholes model is used to determine the price of stock options, which are financial contracts giving the holder the right to buy or sell a stock at a specified price up to a certain time. This model relies on the geometric Brownian motion (GBM) to describe the behavior of stock prices. GBM is defined as:\\n\\\\[ S(t) = S_0 e^{rt - 0.5\\\\sigma^2 t + \\\\sigma x t} \\\\]\\nwhere \\\\( r \\\\) is the risk-free rate, \\\\( \\\\sigma \\\\) is the volatility, and \\\\( x \\\\) is a Weiner process.\\n\\nApplying Ito's Lemma to an option's value function \\\\( V(t, x) \\\\), we derive a partial differential equation (PDE) that governs its evolution. This PDE encapsulates how changes in the option's value over time relate to its spatial derivatives, reflecting the dynamics of the underlying stock price.\\n\\n**Derivation and Implications:**\\nBy solving this PDE using techniques from stochastic calculus, the Black-Scholes model provides a formula for the price of options based on factors such as the current stock price, volatility, time to maturity, risk-free rate, and dividend yield. This formula underpins much of modern financial theory, offering a rigorous framework for option pricing and risk management.\\n\\nIn summary, Ito's Lemma is essential in deriving the Black-Scholes model, demonstrating how stochastic calculus can be applied to real-world financial phenomena, providing tools to manage and mitigate risks effectively.\", additional_kwargs={}, response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-05-04T09:12:49.9080791Z', 'done': True, 'done_reason': 'stop', 'total_duration': 282169689100, 'load_duration': 56846400, 'prompt_eval_count': 39, 'prompt_eval_duration': 1202410600, 'eval_count': 1139, 'eval_duration': 280909103400, 'model_name': 'deepseek-r1:8b'}, id='run-e1da49fa-70c7-4034-9586-b6d3d2217c63-0', usage_metadata={'input_tokens': 39, 'output_tokens': 1139, 'total_tokens': 1178})}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all results if needed\n",
    "all_results = gemma3_results + llama3_1_results + deepseek_r1_results\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 직렬화 가능한 형태로 변환\n",
    "serializable_results = []\n",
    "for result in all_results:\n",
    "    serialized_result = {\n",
    "        \"id\": result.get(\"id\", \"\"),\n",
    "        \"model_name\": result.get(\"model_name\", \"\"),\n",
    "        \"response_content\": result[\"response\"].content if hasattr(result[\"response\"], \"content\") else str(result[\"response\"])\n",
    "    }\n",
    "    serializable_results.append(serialized_result)\n",
    "    \n",
    "# JSON으로 저장\n",
    "with open(\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_results, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
